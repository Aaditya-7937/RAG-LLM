# RAG-LLM â€” AI-Powered Knowledge Retrieval Chatbot

> **Smart answers. Real context. Instant insights.**  
> A next-gen Retrieval-Augmented Generation (RAG) chatbot powered by FAISS, Gemini 2.5 Flash, and FastAPI.

---

## Overview

**RAG-LLM** is a modular chatbot system that combines **semantic retrieval** with **LLM-powered reasoning** to answer questions based on uploaded documents.  
Built for speed, accuracy, and real-world usability.

### Core Highlights
- âš¡ **FastAPI Backend** â€” High-performance, async-driven server.
- ğŸ§  **Google Gemini 2.5 Flash** â€” For lightning-fast response generation.
- ğŸ§­ **FAISS Vector Search** â€” Blazing-fast document retrieval.
- ğŸ“š **Custom File Uploader** â€” Chunk, embed, and index any PDF instantly.
- ğŸ§© **Session-based RAG Pipeline** â€” Each chat maintains history & context.

---

## Architecture

```mermaid
graph TD
    A[ğŸ“„ PDF Upload] -->|Chunk & Embed| B[ğŸ”¢ FAISS Index]
    B -->|Retrieve Relevant Chunks| C[ğŸ§  Gemini 2.5 Flash]
    C -->|Generate Response| D[ğŸ’¬ FastAPI Endpoint]
    D --> E[âš™ï¸ Frontend or API Client]
